{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, x0, hyps):\n",
    "    return np.exp(-.5*np.linalg.norm((x-x0)/hps[1:]))*hps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([4,5.5])\n",
    "x0 = np.array([4.5, 5.7])\n",
    "hps = np.array([1., 2., 2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.874040015387569"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x, x0, hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_torch = torch.from_numpy(x.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_torch = torch.from_numpy(x0.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps_torch = torch.from_numpy(hps.astype(np.float32))\n",
    "hps_torch.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_torch = torch.tensor([4, 5.5], dtype=torch.float32)\n",
    "x0_torch = torch.tensor([4.4, 5.7], dtype=torch.float32)\n",
    "hps_torch = torch.tensor([1., 2., 2.], dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, x0, hps):\n",
    "    return torch.exp(-.5*torch.norm((x-x0)/hps[1:]))*hps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8942, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x_torch, x0_torch, hps_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_res = f(x_torch, x0_torch, hps_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.backward((func_res,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8942, 0.0400, 0.0100])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hps_torch.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps_torch.grad.zero_();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_torch = torch.tensor([4.7, 5.5], dtype=torch.float32)\n",
    "x0_torch = torch.tensor([4.4, 5.7], dtype=torch.float32)\n",
    "hps_torch = torch.tensor([1., 2., 2.], dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9138, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x_torch, x0_torch, hps_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_res = f(x_torch, x0_torch, hps_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.backward((func_res,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9138, 0.0285, 0.0127])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hps_torch.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps_torch.grad.zero_();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hps_torch.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([4,5.5])\n",
    "x0 = np.array([4.5, 5.7])\n",
    "hps = np.array([1., 2., 2.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, x0, hyps):\n",
    "    return np.exp(-.5*np.linalg.norm((x-x0)/hps[1:]))*hps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_torch = torch.from_numpy(x)\n",
    "x0_torch = torch.from_numpy(x0)\n",
    "hps_torch = torch.from_numpy(hps)\n",
    "hps_torch.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.874040015387569"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x_torch, x0_torch, hps_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.874040015387569"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kernel_torch(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        r = x.sum()\n",
    "        ctx.save_for_backward(r)\n",
    "        return r\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        r, = ctx.saved_tensors\n",
    "        return grad_output*r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = kernel_torch.apply(torch.ones(2, requires_grad=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., grad_fn=<kernel_torchBackward>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Function kernel_torchBackward returned an invalid gradient at index 0 - got [] but expected shape compatible with [2] (validate_outputs at /opt/conda/conda-bld/pytorch_1587428266983/work/torch/csrc/autograd/engine.cpp:472)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x4e (0x7f3a15d23b5e in /home/elliott/anaconda3/lib/python3.7/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x2ae3134 (0x7f3a435f8134 in /home/elliott/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #2: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x548 (0x7f3a435f9368 in /home/elliott/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f3a435fb2f2 in /home/elliott/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f3a435f3969 in /home/elliott/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f3a4693a558 in /home/elliott/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #6: <unknown function> + 0xc819d (0x7f3a8561b19d in /home/elliott/anaconda3/lib/python3.7/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6)\nframe #7: <unknown function> + 0x76db (0x7f3a8a0a06db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #8: clone + 0x3f (0x7f3a89dc988f in /lib/x86_64-linux-gnu/libc.so.6)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-1c74fbe29be7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Function kernel_torchBackward returned an invalid gradient at index 0 - got [] but expected shape compatible with [2] (validate_outputs at /opt/conda/conda-bld/pytorch_1587428266983/work/torch/csrc/autograd/engine.cpp:472)\nframe #0: c10::Error::Error(c10::SourceLocation, std::string const&) + 0x4e (0x7f3a15d23b5e in /home/elliott/anaconda3/lib/python3.7/site-packages/torch/lib/libc10.so)\nframe #1: <unknown function> + 0x2ae3134 (0x7f3a435f8134 in /home/elliott/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #2: torch::autograd::Engine::evaluate_function(std::shared_ptr<torch::autograd::GraphTask>&, torch::autograd::Node*, torch::autograd::InputBuffer&) + 0x548 (0x7f3a435f9368 in /home/elliott/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: torch::autograd::Engine::thread_main(std::shared_ptr<torch::autograd::GraphTask> const&, bool) + 0x3d2 (0x7f3a435fb2f2 in /home/elliott/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: torch::autograd::Engine::thread_init(int) + 0x39 (0x7f3a435f3969 in /home/elliott/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: torch::autograd::python::PythonEngine::thread_init(int) + 0x38 (0x7f3a4693a558 in /home/elliott/anaconda3/lib/python3.7/site-packages/torch/lib/libtorch_python.so)\nframe #6: <unknown function> + 0xc819d (0x7f3a8561b19d in /home/elliott/anaconda3/lib/python3.7/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6)\nframe #7: <unknown function> + 0x76db (0x7f3a8a0a06db in /lib/x86_64-linux-gnu/libpthread.so.0)\nframe #8: clone + 0x3f (0x7f3a89dc988f in /lib/x86_64-linux-gnu/libc.so.6)\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.backward((r,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
